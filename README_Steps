1.	Installation of Ollama:
•	Install the Ollama from the official website of ollama “http://ollama.com”.
•	Install the required model from the ollama for the work.


2.	Install the jupyter:
•	Install the anaconda from the official website “http://anaconda.com”.
•	Create a jupyter notebook inside the folder “project fr”.


3.	Connect the mode to jupyter notebook:
•	Build the connection between the model and jupyter notebook by typing in command prompt “llamaenv\scripts\activate”
•	Type “jupyter notebook” to create the python file.


4.	Extract the csv file:
•	Extract the csv file from the internet and install it into the folder,
•	To download the csv file type “https://raw.githubusercontent.com/BUFONJOKER/icc-cwc-dataset/main/icc_cwc.csv"

 
5.	Import the libraries:
•	Import the required libraries for query engine, query pipeline and input component
•	Use pandas to work with csv file.
•	Import the ollama library to run the model locally


6.	Import model into the source file:
•	Import the model into the source file


7.	Write the prompts :
•	To make the model run accordingly, write the prompts for providing the instructions to the model.
•	To specify the quality of the response, write the specific response prompts for the model

8.	Connect the query engine and other modules with the LLM model:
•	Now we will build connection between the modules.
•	To establish the connection, use link function and add_chain function to connect all the modules. 
